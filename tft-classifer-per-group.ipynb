{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:27.348478Z","iopub.status.busy":"2023-06-21T14:30:27.347591Z","iopub.status.idle":"2023-06-21T14:30:27.359824Z","shell.execute_reply":"2023-06-21T14:30:27.358776Z","shell.execute_reply.started":"2023-06-21T14:30:27.348370Z"},"papermill":{"duration":0.023295,"end_time":"2022-06-03T21:13:10.412151","exception":false,"start_time":"2022-06-03T21:13:10.388856","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import gc"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:27.519365Z","iopub.status.busy":"2023-06-21T14:30:27.518908Z","iopub.status.idle":"2023-06-21T14:30:29.390131Z","shell.execute_reply":"2023-06-21T14:30:29.389121Z","shell.execute_reply.started":"2023-06-21T14:30:27.519328Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'2.13.0-rc1'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.405929Z","iopub.status.busy":"2023-06-21T14:30:29.405369Z","iopub.status.idle":"2023-06-21T14:30:29.411266Z","shell.execute_reply":"2023-06-21T14:30:29.409913Z","shell.execute_reply.started":"2023-06-21T14:30:29.405893Z"},"trusted":true},"outputs":[],"source":["input_folder = './predict-student-performance-from-game-play/'"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.413283Z","iopub.status.busy":"2023-06-21T14:30:29.412931Z","iopub.status.idle":"2023-06-21T14:30:29.428413Z","shell.execute_reply":"2023-06-21T14:30:29.427063Z","shell.execute_reply.started":"2023-06-21T14:30:29.413253Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.        \n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            df[col] = df[col].astype('category')\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","    return df"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.432000Z","iopub.status.busy":"2023-06-21T14:30:29.431582Z","iopub.status.idle":"2023-06-21T14:30:29.446793Z","shell.execute_reply":"2023-06-21T14:30:29.445445Z","shell.execute_reply.started":"2023-06-21T14:30:29.431959Z"},"trusted":true},"outputs":[],"source":["# Separate the input features and target variables\n","categorical_ft = [\"event_name\", \"name\", \"page\", \"fqid\", \"room_fqid\", \"text_fqid\"]\n","text_ft = [\"text\"]\n","numerical_ft = [\"elapsed_time\", \"level\", \"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\", \"hover_duration\", \"fullscreen\", \"hq\", \"music\"]"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.449134Z","iopub.status.busy":"2023-06-21T14:30:29.448706Z","iopub.status.idle":"2023-06-21T14:30:29.637914Z","shell.execute_reply":"2023-06-21T14:30:29.636552Z","shell.execute_reply.started":"2023-06-21T14:30:29.449095Z"},"trusted":true},"outputs":[{"data":{"text/plain":["859"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(f\"{input_folder}/train.csv\", nrows=1)\n","categorical_ft_idx = {col: df.columns.get_loc(col) for col in categorical_ft}\n","text_ft_idx = {col: df.columns.get_loc(col) for col in text_ft}\n","numerical_ft_idx = {col: df.columns.get_loc(col) for col in numerical_ft}\n","del df\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Read data in chunks - by group"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.640185Z","iopub.status.busy":"2023-06-21T14:30:29.639361Z","iopub.status.idle":"2023-06-21T14:30:29.651412Z","shell.execute_reply":"2023-06-21T14:30:29.650120Z","shell.execute_reply.started":"2023-06-21T14:30:29.640146Z"},"trusted":true},"outputs":[],"source":["from multiprocessing import Pool, cpu_count\n","from itertools import repeat\n","from functools import partial\n","import os\n","\n","def get_chunk_size(path):\n","    import psutil\n","    svmem = psutil.virtual_memory()\n","    df_sample = pd.read_csv(path, nrows=10)\n","    df_sample_size = df_sample.memory_usage(index=True).sum()\n","    # we divide by 10 because we have selected 10 lines in our df_sample\n","    my_chunk = (1000000000 / df_sample_size)/10\n","    my_chunk = int(my_chunk//1) # we get the integer part\n","    print(f\"Chunk size: {my_chunk}\")\n","    return my_chunk\n","\n","def read_data(dataset, group):\n","\n","    # Check if filtered_df exists and load it if available\n","    file_name = f'filtered_df_{dataset}_{group}.pkl'\n","    if os.path.exists(file_name):\n","        filtered_df = pd.read_pickle(file_name)\n","    else:\n","        path = f'{input_folder}/{dataset}.csv'\n","        chunk_size=get_chunk_size(path)\n","        # Use pandas to read the CSV file and apply the filter function\n","        df_chunks = pd.read_csv(path, chunksize=chunk_size)\n","        filtered_chunks = [chunk[chunk['level_group']==group] for chunk in df_chunks]\n","        # Concatenate the filtered rows into a single DataFrame\n","        filtered_df = reduce_mem_usage(pd.concat(filtered_chunks))\n","        # additional operations\n","        filtered_df['text'] = filtered_df['text'].astype(str)\n","        filtered_df[numerical_ft] = filtered_df[numerical_ft].astype(np.float32).fillna(0)\n","        # Store the filtered_df for future use\n","        filtered_df.to_pickle(file_name)\n","    return filtered_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create LabelEncoder and Scaler"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:29.653531Z","iopub.status.busy":"2023-06-21T14:30:29.653179Z","iopub.status.idle":"2023-06-21T14:30:30.165667Z","shell.execute_reply":"2023-06-21T14:30:30.162183Z","shell.execute_reply.started":"2023-06-21T14:30:29.653499Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizer trained and saved.\n","Label encoder trained and saved.\n","Scaler trained and saved.\n","Max time steps calculated and saved.\n"]}],"source":["import os\n","import joblib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Check if saved transformers exist\n","tokenizer_path = \"tokenizer.pkl\"\n","label_encoder_path = \"label_encoder.pkl\"\n","scaler_path = \"scaler.pkl\"\n","max_time_steps_path = \"max_time_steps.pkl\"\n","\n","# Check if tokenizer was already trained and saved\n","if os.path.exists(tokenizer_path):\n","    tokenizer = joblib.load(tokenizer_path)\n","else:\n","    tokenizer = Tokenizer()\n","    tokenizer.fit_on_texts(pd.read_csv(f\"{input_folder}/train.csv\", usecols=[text_ft_idx['text']]))\n","    joblib.dump(tokenizer, tokenizer_path)\n","    print(\"Tokenizer trained and saved.\")\n","\n","# Check if label encoder was already trained and saved\n","if os.path.exists(label_encoder_path):\n","    label_encoder = joblib.load(label_encoder_path)\n","else:\n","    label_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=299).fit(pd.read_csv(f\"{input_folder}/train.csv\", usecols=[idx for idx in categorical_ft_idx.values()]))\n","    joblib.dump(label_encoder, label_encoder_path)\n","    print(\"Label encoder trained and saved.\")\n","\n","# Check if scaler was already trained and saved\n","if os.path.exists(scaler_path):\n","    scaler = joblib.load(scaler_path)\n","else:\n","    scaler = MinMaxScaler().fit(pd.read_csv(f\"{input_folder}/train.csv\", usecols=[idx for idx in numerical_ft_idx.values()]))\n","    joblib.dump(scaler, scaler_path)\n","    print(\"Scaler trained and saved.\")\n","\n","# Check if max time steps dictionary was already calculated and saved\n","# We calculate here the max time steps to use in padding sequence\n","if os.path.exists(max_time_steps_path):\n","    max_time_steps = joblib.load(max_time_steps_path)\n","else:\n","    df = pd.read_csv(f\"{input_folder}/train.csv\", nrows=1)\n","    a, b = df.columns.get_loc('level_group'), df.columns.get_loc('index')\n","    df = pd.read_csv(f\"{input_folder}/train.csv\", usecols=[a, b])\n","    max_time_steps = df.groupby(['level_group'])['index'].describe()['75%'].to_dict()\n","    max_time_steps = {k: int(min(v, 300)) for k, v in max_time_steps.items()}\n","    joblib.dump(max_time_steps, max_time_steps_path)\n","    print(\"Max time steps calculated and saved.\")\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Format the target"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:30.168514Z","iopub.status.busy":"2023-06-21T14:30:30.167460Z","iopub.status.idle":"2023-06-21T14:30:31.354983Z","shell.execute_reply":"2023-06-21T14:30:31.353864Z","shell.execute_reply.started":"2023-06-21T14:30:30.168464Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(424116, 5)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_id</th>\n","      <th>correct</th>\n","      <th>session</th>\n","      <th>q</th>\n","      <th>level_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20090312431273200_q1</td>\n","      <td>1.0</td>\n","      <td>20090312431273200</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20090312433251036_q1</td>\n","      <td>0.0</td>\n","      <td>20090312433251036</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20090312455206810_q1</td>\n","      <td>1.0</td>\n","      <td>20090312455206810</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20090313091715820_q1</td>\n","      <td>0.0</td>\n","      <td>20090313091715820</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20090313571836404_q1</td>\n","      <td>1.0</td>\n","      <td>20090313571836404</td>\n","      <td>1</td>\n","      <td>0-4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             session_id  correct            session  q level_group\n","0  20090312431273200_q1      1.0  20090312431273200  1         0-4\n","1  20090312433251036_q1      0.0  20090312433251036  1         0-4\n","2  20090312455206810_q1      1.0  20090312455206810  1         0-4\n","3  20090313091715820_q1      0.0  20090313091715820  1         0-4\n","4  20090313571836404_q1      1.0  20090313571836404  1         0-4"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["targets = pd.read_csv(f'{input_folder}/train_labels.csv')\n","targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]) )\n","targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n","targets['correct'] = targets['correct'].astype(np.float32)\n","targets[\"level_group\"] = \"13-22\"\n","targets.loc[(targets.q>3) & (targets.q<=11), \"level_group\"] = \"5-12\"\n","targets.loc[targets.q<=3, \"level_group\"] = \"0-4\"\n","print( targets.shape )\n","targets.head()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:31.356964Z","iopub.status.busy":"2023-06-21T14:30:31.356534Z","iopub.status.idle":"2023-06-21T14:30:33.198799Z","shell.execute_reply":"2023-06-21T14:30:33.197817Z","shell.execute_reply.started":"2023-06-21T14:30:31.356930Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["grouped_targets = targets.groupby(['session', 'level_group'])[\"correct\"].apply(lambda x: x.values.tolist()).reset_index()\n","grouped_targets.rename({\"session\":\"session_id\"}, axis=1, inplace=True)\n","\n","del targets\n","gc.collect()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.201137Z","iopub.status.busy":"2023-06-21T14:30:33.199894Z","iopub.status.idle":"2023-06-21T14:30:33.225618Z","shell.execute_reply":"2023-06-21T14:30:33.224725Z","shell.execute_reply.started":"2023-06-21T14:30:33.201096Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, GlobalAveragePooling1D, Masking, Conv1D, GlobalMaxPooling1D, Lambda, TimeDistributed, BatchNormalization, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import MultiHeadAttention\n","from tensorflow.keras.layers import LSTM, Bidirectional\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data preparation functions"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.227697Z","iopub.status.busy":"2023-06-21T14:30:33.227142Z","iopub.status.idle":"2023-06-21T14:30:33.249115Z","shell.execute_reply":"2023-06-21T14:30:33.248199Z","shell.execute_reply.started":"2023-06-21T14:30:33.227659Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","try:\n","    from keras_preprocessing.sequence import pad_sequences\n","except:\n","    from tensorflow.keras.utils import pad_sequences\n","\n","def process_cat_ft(x, training=True):\n","    # Apply label encoding to categorical variables\n","    for column in x.columns:\n","        x[column] = label_encoders[column].transform(np.array(x[column].values).reshape(-1,1))\n","    return x\n","\n","def padding_sequences(data, idx, cols, padding_len=None):\n","    input = [np.stack(seq) for seq in data.iloc[idx][cols].values]\n","    if padding_len:\n","        return pad_sequences(input, maxlen=padding_len)\n","    return input\n","\n","def prep_data(data, group, grouped_targets=None, training=True):\n","\n","    # Tokenize text field\n","    #if training:\n","    #    tokenizer.fit_on_texts(data['text'])\n","    X_text_sequences = tokenizer.texts_to_sequences(data['text'])\n","    max_text_length = max(len(seq) for seq in X_text_sequences)\n","    data['text_tkn'] = pad_sequences(X_text_sequences, maxlen=max_text_length).tolist()\n","    print(\"Done tokenizing =>\", end=' ')\n","\n","    # min/max scaler\n","    data[numerical_ft] = scaler.transform(data[numerical_ft])\n","    data[categorical_ft] = label_encoder.transform(data[categorical_ft])\n","    if training:\n","        # Get the unique session IDs\n","        unique_session_ids = data.session_id.unique()\n","\n","        # Calculate the number of session IDs to sample\n","        sample_size = int(0.8 * len(unique_session_ids))\n","\n","        # Sample without replacement\n","        train_session_ids = data[data.session_id.isin(training_ids)].session_id.unique()\n","\n","    print(\"Done scaling numericals =>\", end=' ')\n","    num_group = data.groupby(['session_id', 'level_group'])[numerical_ft].apply(lambda x: x.values.tolist()).reset_index()\n","    session_ids = num_group.session_id\n","    numerical_result = num_group.rename({0: \"numerical_ft\"}, axis=1)\n","    categorical_result = data.groupby(['session_id', 'level_group'])[categorical_ft].apply(lambda x: x.values.tolist()).reset_index().rename({0: \"categorical_ft\"}, axis=1)\n","    text_result = data.groupby(['session_id', 'level_group'])['text_tkn'].apply(lambda x: x.values.tolist()).reset_index().rename({0: \"text_ft\"}, axis=1).dropna()\n","    \n","    print(\"Done aggregating =>\", end=' ')\n","\n","    if training: \n","        idx = categorical_result[categorical_result.session_id.isin(train_session_ids)].index\n","        val_idx = categorical_result[~categorical_result.session_id.isin(train_session_ids)].index\n","        \n","        y_target = numerical_result.merge(grouped_targets, on=['session_id', 'level_group'], how='left')['correct']\n","        y = np.array([np.stack(_y) for _y in y_target.iloc[idx].values])\n","\n","        categorical_input_val = padding_sequences(data=categorical_result, idx=val_idx, cols='categorical_ft', padding_len=max_time_steps[group])\n","        text_input_val = padding_sequences(data=text_result, idx=val_idx, cols='text_tkn', padding_len=max_time_steps[group])\n","        numerical_input_val = padding_sequences(data=numerical_result, idx=val_idx, cols='numerical_ft', padding_len=max_time_steps[group])\n","        y_val = np.array([np.stack(_y) for _y in y_target.iloc[val_idx].values])\n","    else:\n","        idx = categorical_result.index\n","        categorical_input_val = None\n","        text_input_val=None\n","        numerical_input_val=None\n","        y_val=None\n","        y=None\n","\n","    # Convert input data to numpy arrays\n","    categorical_input = padding_sequences(data=categorical_result, idx=idx, cols='categorical_ft', padding_len=max_time_steps[group])\n","    text_input = padding_sequences(data=text_result, idx=idx, cols='text_tkn', padding_len=max_time_steps[group])\n","    numerical_input = padding_sequences(data=numerical_result, idx=idx, cols='numerical_ft', padding_len=max_time_steps[group])\n","    \n","    print(\"Done padding.\")\n","\n","    return session_ids, ([categorical_input, text_input, numerical_input], y)\\\n","        , ([categorical_input_val, text_input_val, numerical_input_val], y_val)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### TFT Model - Keras"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.251219Z","iopub.status.busy":"2023-06-21T14:30:33.250605Z","iopub.status.idle":"2023-06-21T14:30:33.267396Z","shell.execute_reply":"2023-06-21T14:30:33.266287Z","shell.execute_reply.started":"2023-06-21T14:30:33.251184Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import MultiHeadAttention\n","from tensorflow.keras.models import load_model\n","\n","def create_tf_model(max_time_steps, num_categories, max_text_length, num_time_series, nb_questions):\n","    # Define input layers\n","    categorical_input = Input(shape=(max_time_steps, num_categories), name='categorical_input')\n","    text_input = Input(shape=(max_time_steps, max_text_length), name='text_input')\n","    time_series_input = Input(shape=(max_time_steps, num_time_series), name='time_series_input')\n","    \n","    # Concatenate all inputs\n","    input_concat = Concatenate()([categorical_input, text_input, time_series_input])\n","    \n","    # Temporal fusion transformer encoding layers\n","    num_layers = 4  # Number of encoding layers\n","    num_heads = 4  # Number of attention heads\n","    hidden_units = num_categories + max_text_length + num_time_series  # Number of units in the hidden layer\n","    \n","    x = input_concat\n","    for _ in range(num_layers):\n","        # Self-attention layer\n","        attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=hidden_units)(x, x)\n","        attn_output = BatchNormalization()(attn_output)\n","        attn_output = Dropout(0.2)(attn_output)\n","        x = x + attn_output\n","    \n","        # Feed-forward network\n","        ff_output = Dense(hidden_units, activation='relu')(x)\n","        ff_output = BatchNormalization()(ff_output)\n","        ff_output = Dropout(0.2)(ff_output)\n","        x = x + ff_output\n","\n","    from tensorflow.keras import initializers\n","    \n","    x = Flatten()(x)\n","    # Fully connected layers\n","    x = Dense(128, activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.1))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    \n","    x = Dense(64, activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.1))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    \n","    x = Dense(32, activation='relu', kernel_initializer=initializers.RandomNormal(stddev=0.1))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    \n","    # Output layer\n","    output = Dense(nb_questions, activation='sigmoid')(x)\n","\n","\n","    # Create the model\n","    model = Model(inputs=[categorical_input, text_input, time_series_input], outputs=output)\n","\n","    return model\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.271400Z","iopub.status.busy":"2023-06-21T14:30:33.271046Z","iopub.status.idle":"2023-06-21T14:30:33.286899Z","shell.execute_reply":"2023-06-21T14:30:33.285968Z","shell.execute_reply.started":"2023-06-21T14:30:33.271369Z"},"trusted":true},"outputs":[],"source":["import tensorflow.keras.backend as K\n","\n","try:\n","    from tensorflow.keras.optimizers.legacy import Adam\n","except:\n","    from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","import copy \n","\n","def get_f1_score(num_classes):\n","    try:\n","        from tensorflow.keras.metrics import F1Score\n","        f1_score = F1Score(average='macro')\n","    except:\n","        from tensorflow_addons.metrics import F1Score\n","        f1_score = F1Score(num_classes=num_classes, average='macro')\n","    return f1_score\n","\n","# Learning rate scheduler\n","def lr_scheduler(epoch, lr):\n","    decay_rate = 0.1\n","    decay_step = 5\n","    if epoch % decay_step == 0 and epoch > 0:\n","        return lr * decay_rate\n","    return lr\n","\n","def focal_loss(gamma=2.0, alpha=0.25):\n","    def loss_function(y_true, y_pred):\n","        # Cast y_true to the same data type as y_pred\n","        y_true = K.cast(y_true, K.dtype(y_pred))\n","        # Calculate the focal loss for each element in the output vector\n","        epsilon = K.epsilon()\n","        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n","        cross_entropy = -y_true * K.log(y_pred)\n","        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n","\n","        # Calculate the average loss across all elements\n","        loss = K.mean(loss, axis=-1)\n","\n","        return loss\n","    \n","    return loss_function\n","\n","def jaccard_loss():\n","    def loss_function(y_true, y_pred):\n","        intersection = K.sum(y_true * y_pred, axis=-1)\n","        union = K.sum(y_true + y_pred, axis=-1) - intersection\n","        jaccard = (intersection + 1e-6) / (union + 1e-6)\n","        loss = 1 - jaccard\n","        return loss\n","    return loss_function\n","\n","def find_optimal_threshold(y_true, y_pred):\n","    from sklearn.metrics import f1_score\n","    best_threshold = 0.0\n","    best_f1_score = 0.0\n","    \n","    for threshold in np.arange(0.0, 1.01, 0.01):\n","        y_pred_binary = (y_pred > threshold).astype(int)\n","        f1 = f1_score(y_true, y_pred_binary, average='macro')\n","        \n","        if f1 > best_f1_score:\n","            best_f1_score = f1\n","            best_threshold = threshold\n","    \n","    return best_threshold"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.288802Z","iopub.status.busy":"2023-06-21T14:30:33.288121Z","iopub.status.idle":"2023-06-21T14:30:33.304092Z","shell.execute_reply":"2023-06-21T14:30:33.302781Z","shell.execute_reply.started":"2023-06-21T14:30:33.288745Z"},"trusted":true},"outputs":[],"source":["def training_round(X, y, X_val, y_val, **kwargs):\n","    if kwargs['iteration'] == 0:\n","        # Create the model\n","        model = create_tf_model(max_time_steps=kwargs['max_time_steps'], \n","                                num_time_series=kwargs['num_time_series'], \n","                                num_categories=kwargs['num_categories'], \n","                                nb_questions=kwargs['nb_questions'], \n","                                max_text_length=kwargs['max_text_length'])\n","        learning_rate = 0.0001  # Initial learning rate\n","    else:\n","        model = load_model(kwargs['model_path'], custom_objects={'F1Score': get_f1_score(kwargs['nb_questions'])})\n","        previous_optimizer = model.optimizer\n","        learning_rate = K.get_value(previous_optimizer.lr)  # Get the learning rate from the previous optimizer\n","\n","    total_params = model.count_params()\n","    print(\"Total number of model parameters:\", total_params)\n","\n","    # Compile and train the model\n","    optimizer = Adam(learning_rate=learning_rate)  # Use the same learning rate\n","    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[kwargs['eval_metric']])\n","    lr_callback = LearningRateScheduler(lr_scheduler)\n","    model.fit(X, y,\n","              batch_size=128, \n","              epochs=5,\n","              validation_data=(X_val, y_val),\n","              callbacks=[lr_callback, EarlyStopping(patience=10)])\n","    model.save(kwargs['model_path'])\n","    return model\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.305959Z","iopub.status.busy":"2023-06-21T14:30:33.305629Z","iopub.status.idle":"2023-06-21T14:30:33.353066Z","shell.execute_reply":"2023-06-21T14:30:33.351909Z","shell.execute_reply.started":"2023-06-21T14:30:33.305929Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('Training ids:', 20027, ' Validation ids: ', 3535)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["import random\n","session_ids = list(grouped_targets.session_id.unique())\n","sample_size = int(len(session_ids) * 0.85)\n","training_ids = random.sample(session_ids, sample_size)\n","val_ids = grouped_targets[~grouped_targets.session_id.isin(training_ids)].session_id.unique()\n","\"Training ids:\", len(training_ids), \" Validation ids: \", len(val_ids)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-21T14:30:33.354882Z","iopub.status.busy":"2023-06-21T14:30:33.354514Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["======= Training 0-4 ===========\n","Reading group: 0-4 (785855, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:43:09.735890: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n","2023-06-21 15:43:09.735910: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n","2023-06-21 15:43:09.735918: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n","2023-06-21 15:43:09.735949: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2023-06-21 15:43:09.735964: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]},{"name":"stdout","output_type":"stream","text":["Total number of model parameters: 294467\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:43:11.410239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.8818 - f1_score: 0.4827"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:43:24.658183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 17s 454ms/step - loss: 0.8818 - f1_score: 0.4827 - val_loss: 0.9089 - val_f1_score: 0.4747 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 11s 374ms/step - loss: 0.8578 - f1_score: 0.4838 - val_loss: 0.7821 - val_f1_score: 0.4640 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 11s 368ms/step - loss: 0.8523 - f1_score: 0.4796 - val_loss: 0.7434 - val_f1_score: 0.4680 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 10s 361ms/step - loss: 0.8205 - f1_score: 0.4799 - val_loss: 0.7145 - val_f1_score: 0.4728 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 11s 367ms/step - loss: 0.8132 - f1_score: 0.4822 - val_loss: 0.7034 - val_f1_score: 0.4740 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(784332, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 294467\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:44:17.275007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.7891 - f1_score: 0.4875"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:44:32.935195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 19s 541ms/step - loss: 0.7891 - f1_score: 0.4875 - val_loss: 0.7043 - val_f1_score: 0.4849 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 11s 374ms/step - loss: 0.7787 - f1_score: 0.4894 - val_loss: 0.6861 - val_f1_score: 0.4840 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 11s 372ms/step - loss: 0.7650 - f1_score: 0.4898 - val_loss: 0.6733 - val_f1_score: 0.4838 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 11s 366ms/step - loss: 0.7583 - f1_score: 0.4890 - val_loss: 0.6665 - val_f1_score: 0.4852 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 11s 376ms/step - loss: 0.7461 - f1_score: 0.4872 - val_loss: 0.6600 - val_f1_score: 0.4900 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(773312, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 294467\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:45:27.275277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.7408 - f1_score: 0.4862"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:45:43.729934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 20s 551ms/step - loss: 0.7408 - f1_score: 0.4862 - val_loss: 0.6526 - val_f1_score: 0.4875 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 11s 384ms/step - loss: 0.7304 - f1_score: 0.4880 - val_loss: 0.6453 - val_f1_score: 0.4871 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 11s 373ms/step - loss: 0.7231 - f1_score: 0.4879 - val_loss: 0.6399 - val_f1_score: 0.4863 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 11s 369ms/step - loss: 0.7104 - f1_score: 0.4895 - val_loss: 0.6347 - val_f1_score: 0.4886 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 11s 370ms/step - loss: 0.7027 - f1_score: 0.4905 - val_loss: 0.6307 - val_f1_score: 0.4886 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(773097, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 294467\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:46:38.215383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.6976 - f1_score: 0.4835"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:46:57.350534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 23s 642ms/step - loss: 0.6976 - f1_score: 0.4835 - val_loss: 0.6235 - val_f1_score: 0.4911 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 11s 391ms/step - loss: 0.6908 - f1_score: 0.4865 - val_loss: 0.6190 - val_f1_score: 0.4894 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 11s 371ms/step - loss: 0.6865 - f1_score: 0.4856 - val_loss: 0.6153 - val_f1_score: 0.4878 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 11s 368ms/step - loss: 0.6739 - f1_score: 0.4880 - val_loss: 0.6155 - val_f1_score: 0.4882 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 11s 367ms/step - loss: 0.6715 - f1_score: 0.4900 - val_loss: 0.6096 - val_f1_score: 0.4863 - lr: 1.0000e-04\n","======= Predicting 0-4 ===========\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","2023-06-21 15:47:43.792597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 4s 95ms/step\n","Optimal threshold:  0.31\n","Done tokenizing => Done scaling numericals => Done aggregating => Done padding.\n"," 2/32 [>.............................] - ETA: 1s"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 2s 63ms/step\n","======= Training 5-12 ===========\n","Reading group: 5-12 (1742725, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 644840\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:48:05.779071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.9125 - f1_score: 0.2107"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:48:49.098393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 51s 2s/step - loss: 0.9125 - f1_score: 0.2107 - val_loss: 1.0905 - val_f1_score: 0.1779 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.8926 - f1_score: 0.2122 - val_loss: 0.8365 - val_f1_score: 0.1958 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.8738 - f1_score: 0.2071 - val_loss: 0.7610 - val_f1_score: 0.2009 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.8544 - f1_score: 0.2101 - val_loss: 0.7259 - val_f1_score: 0.2050 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.8439 - f1_score: 0.2109 - val_loss: 0.7112 - val_f1_score: 0.2071 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(1750852, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 644840\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:51:44.027932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.8315 - f1_score: 0.2084"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:52:30.817569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 54s 2s/step - loss: 0.8315 - f1_score: 0.2084 - val_loss: 0.6971 - val_f1_score: 0.2021 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 39s 1s/step - loss: 0.8234 - f1_score: 0.2093 - val_loss: 0.6877 - val_f1_score: 0.2038 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.8100 - f1_score: 0.2121 - val_loss: 0.6807 - val_f1_score: 0.2040 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.8006 - f1_score: 0.2110 - val_loss: 0.6758 - val_f1_score: 0.2053 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.7879 - f1_score: 0.2110 - val_loss: 0.6723 - val_f1_score: 0.2024 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(1741033, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 644840\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:55:23.666169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.7879 - f1_score: 0.2086"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:56:10.876817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 55s 2s/step - loss: 0.7879 - f1_score: 0.2086 - val_loss: 0.6687 - val_f1_score: 0.2073 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 39s 1s/step - loss: 0.7773 - f1_score: 0.2064 - val_loss: 0.6702 - val_f1_score: 0.2070 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.7708 - f1_score: 0.2116 - val_loss: 0.6671 - val_f1_score: 0.2070 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.7585 - f1_score: 0.2117 - val_loss: 0.6670 - val_f1_score: 0.2079 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.7555 - f1_score: 0.2131 - val_loss: 0.6656 - val_f1_score: 0.2112 - lr: 1.0000e-04\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["(1734770, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 644840\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:59:05.504959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.7469 - f1_score: 0.2136"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 15:59:53.802131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 56s 2s/step - loss: 0.7469 - f1_score: 0.2136 - val_loss: 0.6662 - val_f1_score: 0.2163 - lr: 1.0000e-04\n","Epoch 2/5\n","29/29 [==============================] - 38s 1s/step - loss: 0.7372 - f1_score: 0.2156 - val_loss: 0.6645 - val_f1_score: 0.2121 - lr: 1.0000e-04\n","Epoch 3/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.7389 - f1_score: 0.2113 - val_loss: 0.6621 - val_f1_score: 0.2120 - lr: 1.0000e-04\n","Epoch 4/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.7282 - f1_score: 0.2159 - val_loss: 0.6589 - val_f1_score: 0.2116 - lr: 1.0000e-04\n","Epoch 5/5\n","29/29 [==============================] - 37s 1s/step - loss: 0.7268 - f1_score: 0.2147 - val_loss: 0.6560 - val_f1_score: 0.2136 - lr: 1.0000e-04\n","======= Predicting 5-12 ===========\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","2023-06-21 16:02:30.902901: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 8s 212ms/step\n","Optimal threshold:  0.19\n","Done tokenizing => Done scaling numericals => Done aggregating => Done padding.\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["32/32 [==============================] - 5s 168ms/step\n","======= Training 13-22 ===========\n","Reading group: 13-22 (2648801, 20)\n","Done tokenizing => Done scaling numericals => Done aggregating => "]},{"name":"stderr","output_type":"stream","text":["/Users/mehditantaoui/Documents/Challenges/tftClassifier/.venv/lib/python3.10/site-packages/keras/src/utils/data_utils.py:1130: RuntimeWarning: invalid value encountered in cast\n","  trunc = np.asarray(trunc, dtype=dtype)\n"]},{"name":"stdout","output_type":"stream","text":["Done padding.\n","Total number of model parameters: 644807\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 16:03:07.195382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - ETA: 0s - loss: 0.9303 - f1_score: 0.2373"]},{"name":"stderr","output_type":"stream","text":["2023-06-21 16:03:55.113054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 56s 2s/step - loss: 0.9303 - f1_score: 0.2373 - val_loss: 1.1866 - val_f1_score: 0.2037 - lr: 1.0000e-04\n","Epoch 2/5\n","13/29 [============>.................] - ETA: 18s - loss: 0.9242 - f1_score: 0.2300"]}],"source":["train = True\n","    \n","models = {group: f\"model_{group}.h5\" for group in ['0-4', '5-12', '13-22']}\n","thresholds = {group: 0.5 for group in ['0-4', '5-12', '13-22']}\n","training_session_perc = 0.2\n","val_size = 1000\n","for group in ['0-4', '5-12', '13-22']:\n","    if not train:\n","        break\n","    print(f\"======= Training {group} ===========\")\n","    print(\"Reading group:\",group, end=' ')\n","    for i in range(4):\n","        sub_data = read_data('train', group=group)\n","        sessions=np.concatenate((\\\n","                                 np.random.choice(training_ids, int(len(training_ids)*training_session_perc)),\n","                                 random.sample(list(val_ids), val_size)\n","                                ))\n","        sub_data = sub_data[sub_data.session_id.isin(sessions)]\n","        print(sub_data.shape)\n","        _, ([categorical_input, text_input, numerical_input], y)\\\n","        ,([categorical_input_val, text_input_val, numerical_input_val], y_val) = \\\n","        prep_data(sub_data, group, grouped_targets, training=True)\n","        # Define the number of time series, categorical fields, and classes\n","        num_time_series = len(numerical_ft)\n","        num_categories = len(categorical_ft)\n","        nb_questions = y.shape[1]  # Assuming there are 18 questions per level group\n","        vocab_size = len(tokenizer.word_index) + 1\n","        max_text_length = text_input.shape[-1]\n","        f1_score = get_f1_score(nb_questions)\n","        params = {\n","            \"max_time_steps\": max_time_steps[group],\n","            \"num_time_series\" : num_time_series,\n","            \"nb_questions\": nb_questions,\n","            \"max_text_length\":max_text_length,\n","            \"num_categories\":num_categories,\n","            \"eval_metric\": f1_score,\n","            \"iteration\": i,\n","            \"model_path\": f\"model_{group}.h5\"\n","        }\n","        model = training_round(\n","            X=[categorical_input, text_input, numerical_input],\n","            y=y,\n","            X_val=[categorical_input_val, text_input_val, numerical_input_val],\n","            y_val=y_val,\n","            **params\n","        )\n","        \n","    models[group] = f\"model_{group}.h5\"\n","    print(f\"======= Predicting {group} ===========\")\n","    # Obtain predictions on the validation set\n","    y_pred_val = model.predict([categorical_input_val, text_input_val, numerical_input_val])\n","\n","    # Find the optimal threshold\n","    optimal_threshold = find_optimal_threshold(y_val, y_pred_val)\n","    thresholds[group] = optimal_threshold\n","    print(\"Optimal threshold: \", optimal_threshold)\n","    data = read_data('test', group=group)\n","    sessions_id, ([categorical_input, text_input, numerical_input], y)\\\n","    ,([_, _, _], _) = prep_data(data, group, None, training=False)\n","    y_pred_val = model.predict([categorical_input_val, text_input_val, numerical_input_val])\n","    y_pred_binary = (y_pred_val > optimal_threshold).astype(int)\n","\n","    result = pd.DataFrame(zip(sessions_id, y_pred_binary), columns=['session_id', 'correct'])\n","    result = result.explode('correct', ignore_index=False)\n","    result['session_id'] = result['session_id'].apply(lambda x: str(x)+ '_q') + (result.groupby('session_id').cumcount()+1).astype(str)\n","    result.to_csv(f\"submission_{group}.csv\", index=False)    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import jo_wilder\n","env = jo_wilder.make_env()\n","iter_test = env.iter_test()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.337707,"end_time":"2022-06-03T21:13:10.798069","exception":false,"start_time":"2022-06-03T21:13:10.460362","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","counter = 0\n","# The API will deliver two dataframes in this specific order,\n","# for every session+level grouping (one group per session for each checkpoint)\n","for (test, sample_submission) in iter_test:\n","    test['text'] = test['text'].astype(str)\n","    test[numerical_ft] = test[numerical_ft].fillna(0)\n","    if counter == 0:\n","        print(test.shape)\n","        print(sample_submission.head())\n","        \n","    list_df = []\n","    for group, model_path in models.items():\n","        if test[test.level_group==group].shape[0] == 0:\n","            continue\n","        print(f\"==== Submission {group} - Model {model_path}\")\n","        #print(test[test.level_group==group].head())\n","        sessions_id, ([categorical_input, text_input, numerical_input], y)\\\n","        ,([_, _, _], _) = prep_data(test[test.level_group==group].copy(), group, None, training=False)\n","        ## users make predictions here using the test data\n","        model = load_model(model_path, custom_objects={'F1Score': get_f1_score(3)})\n","        y_pred_val = model.predict([categorical_input, text_input, numerical_input])\n","        y_pred_binary = (y_pred_val > thresholds[group]).astype(int)\n","\n","        result = pd.DataFrame(zip(sessions_id, y_pred_binary), columns=['session_id', 'correct'])\n","        result = result.explode('correct', ignore_index=False)\n","        result['session_id'] = result['session_id'].apply(lambda x: str(x)+ '_q') + (result.groupby('session_id').cumcount()+1).astype(str)\n","        list_df.append(result)\n","        print(sessions_id)\n","    #final_result = pd.concat(list_df)\n","    #submission_merged=final_result.merge(sample_submission, on='session_id', how='left')\n","    # Replace values in column B of df1 with values from merged_df\n","    \n","    sample_submission = pd.concat(list_df)\n","    env.predict(sample_submission)\n","    counter += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":0.767504,"end_time":"2022-06-03T21:13:11.572788","exception":false,"start_time":"2022-06-03T21:13:10.805284","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["## the end result is a submission file containing all test session predictions\n","! head submission.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
